# -*- coding: utf-8 -*-
"""10.1 Heart_disease_project.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1POBGlqldb-nJUI9AVQxGSapW2FhMr8Ay

Important parameters:
    Number of instances: 302
    Number of attributes: 14 continuos attributes
Each of the attributes:
    age: Age in years
    sex: Sex(1= male, 0= female)
    cp: Chest pain type (Value 1: typical angina, Value 2: atypical angina, Value3: non-aginal pain, Value 4: asymptomatic)
    trestbps: Resting blood pressure (in mmHg on admission to the hospital)
    chol: Serum Cholestoral in mg/dl
    fbs: fast blood sugar > 120 mg/dl (1= true, 0=false)
    restecg: Resting electrocardiographic results (0: normal, 1: having ST-T wave abnormality (T wave inversions and/or St elevation or depression of > 0.05mV, 2: showing probabal or definite left ventricular hypertrophy by Estes'criteria)
    thalach: Maximum heart rate achieved
    exang: Excercise included angina (1= yes, 0=no)
    oldpeak: ST depression indced by exercise relative to rest
    slope: the slope of the peak exercise ST segment (Value 1: upsloping, Value 2: flat, Value 3: downsloping)
    ca : Number of major vessels (0-3) colored by flourosopy
    thal: 3= normal, 6= fixed defect, 7= reversable defect
    HeartDisease: Diagnosis of heart disease- angiprahic disease status (Value 0: <50% diameter narrowing, Value 1: > 50% diameter narrowing) in any major vessel: attributes 59 through 68 are vessels
"""

import pandas as pd

from google.colab import drive
drive.mount('/content/drive')

# Commented out IPython magic to ensure Python compatibility.
# %cd /content/drive/My Drive/Colab Notebooks

#Import data
HDNames= ['age','sex','cp','trestbps','chol','fbs','restecg','thalach','exang','oldpeak','slope','ca','hal','HeartDisease']
Data = pd.read_excel('/content/4.1 Ch3.ClevelandData.xlsx', names=HDNames)

print(Data.head(20))
print(Data.info())
summary = Data.describe()
print(summary)

"""Exploratory Analysis

"""

#anomaly

"""
Pandas dtype : object -> python dtype is string ->  usage is text
Pandas dtype : int64 -> python dtype is int ->  usage is integer numbers
Pandas dtype : float64 -> python dtype is float ->  usage is floating point numbers

"""

#Removing missing values
import numpy as np

DataNew = Data.replace('?', np.nan)

print(DataNew.info())

print(DataNew.describe())

print(DataNew.isnull().sum())

"""

*   Replace the values with constant values
*   Set the values with other columns' values


*  Transform the data with functions
*   Delete rows



"""

DataNew = DataNew.dropna()

print(DataNew.info())

print(DataNew.isnull().sum())

"""x(scaled) = (x-mean)/sd

Mean = 0
standard deviation = 1

*   Value > mean will have +z score
*   Value < mean will have -z score
"""

InputNames = HDNames
InputNames.pop()

Input = pd.DataFrame(DataNew.iloc[:, 0:13],columns=InputNames)

Target = pd.DataFrame(DataNew.iloc[:, 13],columns=['HeartDisease'])

from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()
print(scaler.fit(Input))

InputScaled = scaler.fit_transform(Input)

InputScaled = pd.DataFrame(InputScaled,columns=InputNames)

summary = InputScaled.describe()
summary = summary.transpose()
print(summary)

import matplotlib.pyplot as plt
boxplot = InputScaled.boxplot(column=InputNames,showmeans=True)
plt.show()

pd.plotting.scatter_matrix(InputScaled, figsize=(6, 6))
plt.show()

CorData = InputScaled.corr(method='pearson')

with pd.option_context('display.max_rows', None, 'display.max_columns', CorData.shape[1]):
    print(CorData)

plt.matshow(CorData)
plt.xticks(range(len(CorData.columns)), CorData.columns)
plt.yticks(range(len(CorData.columns)), CorData.columns)
plt.colorbar()
plt.show()

#Split the data
from sklearn.model_selection import train_test_split

Input_train, Input_test, Target_train, Target_test = train_test_split(InputScaled, Target, test_size = 0.30, random_state = 5)
print(Input_train.shape)
print(Input_test.shape)
print(Target_train.shape)
print(Target_test.shape)

"""test_size = 0.3 means that 30 % of the data is divided up as data set.          
random_state parameter is used to set the seed used by the random number generator.                                                                      
InputScaled and Target parameters are inputs and target DataFrames.

207 rows (Input_train) and 89 rows(input_test)

Create a keras Sequential model


*   Import the Sequential class from keras.models
*   Stack the layers using the .add() method


*   Configure the learning process and using the .compile() method
*   Train the model on teh train dataset using the .fit() method
"""

from keras.models import Sequential
from keras.layers import Dense

model = Sequential()
model.add(Dense(30, input_dim=13, activation='tanh'))
model.add(Dense(20, activation='tanh'))
model.add(Dense(1, activation='sigmoid'))

model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])
model.fit(Input_train, Target_train, epochs=1000, verbose=1)

model.summary()

score = model.evaluate(Input_test, Target_test, verbose = 0)
print('Keras Model Acccuracy= ',score[1])

Target_Classifcation = model.predict(Input_test)
Target_Classifcation  = (Target_Classifcation >0.5)

from sklearn.metrics import confusion_matrix
print(confusion_matrix(Target_test, Target_Classifcation))

36+37

"""73 observations of 89 were correctly classified by making 16 errors with an accuracy qual to 0.82

*   Input_train: Aarry of input training data
*   Target_train:Aarry of target (label)data


*   epochs = 1000: Number of epochs to train the model. An epoch is an iteration over the entire  x and y data provided
*   verbose = 1: An integer, either 0,1,or 2. Verbose mode: 0 =silent, 1= progress bar, 2= one line per epoch

Three argiments are passed:


*   The dam optimizer: An algorithm for the first-order gradient-based optimization of stochastic objective functions, based on adaptive estimates of lower-order moments
*   The binary_crossentropy loss function: we will use logarithmic loss, which for a binary classification problme is defined in Keras as binary_crossentropy


*   The accuracy metrhic: A metric is a function that is used to evaluate the performance of your model during training and testing
"""